{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de6a055b",
   "metadata": {},
   "source": [
    "## Kalman Filter for X, Y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75662e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch\n",
    "\n",
    "def load_poses(path, sc_factor=1.0):\n",
    "    poses = []\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        c2w = np.array(list(map(float, line.split()))).reshape(4, 4)\n",
    "        c2w[:3, 1] *= -1\n",
    "        c2w[:3, 2] *= -1\n",
    "        c2w[:3, 3] *= sc_factor\n",
    "        c2w = torch.from_numpy(c2w).float()\n",
    "        poses.append(c2w)\n",
    "    return poses\n",
    "\n",
    "def extract_positions(poses):\n",
    "    positions = []\n",
    "    for pose in poses:\n",
    "        position = pose[:3, 3].numpy()\n",
    "        positions.append(position)  # Now including all x, y, z\n",
    "    return np.array(positions)\n",
    "\n",
    "class KalmanFilter:\n",
    "    def __init__(self, initial_state, initial_P, F, H, Q, R):\n",
    "        self.state = initial_state\n",
    "        self.P = initial_P\n",
    "        self.F = F\n",
    "        self.H = H\n",
    "        self.Q = Q\n",
    "        self.R = R\n",
    "    \n",
    "    def predict(self):\n",
    "        self.state = np.dot(self.F, self.state)\n",
    "        self.P = np.dot(np.dot(self.F, self.P), self.F.T) + self.Q\n",
    "    \n",
    "    def update(self, measurement):\n",
    "        y = measurement - np.dot(self.H, self.state)\n",
    "        S = np.dot(np.dot(self.H, self.P), self.H.T) + self.R\n",
    "        K = np.dot(np.dot(self.P, self.H.T), np.linalg.inv(S))\n",
    "        self.state = self.state + np.dot(K, y)\n",
    "        self.P = self.P - np.dot(np.dot(K, self.H), self.P)\n",
    "\n",
    "# Load and prepare data\n",
    "poses = load_poses('./data/Replica/room1/traj.txt', sc_factor=1.0)\n",
    "positions = extract_positions(poses)\n",
    "\n",
    "# Add some noise to the measurements\n",
    "noise_std_dev = 0.001\n",
    "noisy_positions = positions + np.random.normal(0, noise_std_dev, positions.shape)\n",
    "\n",
    "# Initialize Kalman Filter\n",
    "dt = 1.0  # time step\n",
    "F = np.array([[1, 0, 0, dt, 0, 0],\n",
    "              [0, 1, 0, 0, dt, 0],\n",
    "              [0, 0, 1, 0, 0, dt],\n",
    "              [0, 0, 0, 1, 0, 0],\n",
    "              [0, 0, 0, 0, 1, 0],\n",
    "              [0, 0, 0, 0, 0, 1]])\n",
    "H = np.array([[1, 0, 0, 0, 0, 0],\n",
    "              [0, 1, 0, 0, 0, 0],\n",
    "              [0, 0, 1, 0, 0, 0]])\n",
    "Q = np.eye(6) * 0.01\n",
    "R = np.eye(3) * 0.1\n",
    "initial_state = np.array([positions[0][0], positions[0][1], positions[0][2], 0, 0, 0])\n",
    "initial_P = np.eye(6)\n",
    "\n",
    "kf = KalmanFilter(initial_state, initial_P, F, H, Q, R)\n",
    "\n",
    "# Apply Kalman Filter\n",
    "filtered_positions = []\n",
    "for pos in noisy_positions:\n",
    "    kf.predict()\n",
    "    kf.update(pos)\n",
    "    filtered_positions.append(kf.state[:3])\n",
    "\n",
    "filtered_positions = np.array(filtered_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f6bcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(positions[:, 0], positions[:, 1], positions[:, 2], 'g-', label='True Trajectory')\n",
    "ax.plot(noisy_positions[:, 0], noisy_positions[:, 1], noisy_positions[:, 2], 'r.', label='Noisy Measurements')\n",
    "ax.plot(filtered_positions[:, 0], filtered_positions[:, 1], filtered_positions[:, 2], 'b-', label='Kalman Filter Estimate')\n",
    "ax.legend()\n",
    "ax.set_title('3D Kalman Filter on Camera Trajectory Data')\n",
    "ax.set_xlabel('X position')\n",
    "ax.set_ylabel('Y position')\n",
    "ax.set_zlabel('Z position')\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Number of poses processed: {len(positions)}\")\n",
    "print(f\"Noise standard deviation: {noise_std_dev}\")\n",
    "print(f\"Process noise covariance (Q) diagonal: {np.diagonal(Q)}\")\n",
    "print(f\"Measurement noise covariance (R) diagonal: {np.diagonal(R)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070939d8",
   "metadata": {},
   "source": [
    "##\n",
    "## Making sure the 3d plot is valid by ploting 2 - 2d plots\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b5c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "# 3D plot\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "ax1.plot(positions[:, 0], positions[:, 1], positions[:, 2], 'g-', label='True Trajectory')\n",
    "ax1.plot(noisy_positions[:, 0], noisy_positions[:, 1], noisy_positions[:, 2], 'r.', label='Noisy Measurements')\n",
    "ax1.plot(filtered_positions[:, 0], filtered_positions[:, 1], filtered_positions[:, 2], 'b-', label='Kalman Filter Estimate')\n",
    "ax1.legend()\n",
    "ax1.set_title('3D Trajectory')\n",
    "ax1.set_xlabel('X position')\n",
    "ax1.set_ylabel('Y position')\n",
    "ax1.set_zlabel('Z position')\n",
    "\n",
    "# X-Y projection (top-down view)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.plot(positions[:, 0], positions[:, 1], 'g-', label='True Trajectory')\n",
    "ax2.plot(noisy_positions[:, 0], noisy_positions[:, 1], 'r.', label='Noisy Measurements')\n",
    "ax2.plot(filtered_positions[:, 0], filtered_positions[:, 1], 'b-', label='Kalman Filter Estimate')\n",
    "ax2.legend()\n",
    "ax2.set_title('X-Y Projection (Top-down View)')\n",
    "ax2.set_xlabel('X position')\n",
    "ax2.set_ylabel('Y position')\n",
    "ax2.grid(True)\n",
    "\n",
    "# Y-Z projection (side view)\n",
    "ax3 = fig.add_subplot(133)\n",
    "ax3.plot(positions[:, 1], positions[:, 2], 'g-', label='True Trajectory')\n",
    "ax3.plot(noisy_positions[:, 1], noisy_positions[:, 2], 'r.', label='Noisy Measurements')\n",
    "ax3.plot(filtered_positions[:, 1], filtered_positions[:, 2], 'b-', label='Kalman Filter Estimate')\n",
    "ax3.legend()\n",
    "ax3.set_title('Y-Z Projection (Side View)')\n",
    "ax3.set_xlabel('Y position')\n",
    "ax3.set_ylabel('Z position')\n",
    "ax3.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a60f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df511c61",
   "metadata": {},
   "source": [
    "## Full matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb56aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def load_poses(path, sc_factor=1.0):\n",
    "    poses = []\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        c2w = torch.tensor(list(map(float, line.split()))).reshape(4, 4)\n",
    "        c2w[:3, 1] *= -1\n",
    "        c2w[:3, 2] *= -1\n",
    "        c2w[:3, 3] *= sc_factor\n",
    "        poses.append(c2w)\n",
    "    return poses\n",
    "\n",
    "def matrix_to_vector(pose_matrix, use_full_pose=False):\n",
    "    if use_full_pose:\n",
    "        # Extract rotation matrix (3x3) and translation vector (3x1)\n",
    "        rotation = pose_matrix[:3, :3]\n",
    "        translation = pose_matrix[:3, 3]\n",
    "        # Flatten rotation matrix and concatenate with translation\n",
    "        return torch.cat([rotation.flatten(), translation])\n",
    "    else:\n",
    "        # Return only the translation vector\n",
    "        return pose_matrix[:3, 3]\n",
    "\n",
    "class KalmanFilter:\n",
    "    def __init__(self, initial_state, initial_P, F, H, Q, R):\n",
    "        self.state = initial_state\n",
    "        self.P = initial_P\n",
    "        self.F = F\n",
    "        self.H = H\n",
    "        self.Q = Q\n",
    "        self.R = R\n",
    "    \n",
    "    def predict(self):\n",
    "        self.state = torch.matmul(self.F, self.state)\n",
    "        self.P = torch.matmul(torch.matmul(self.F, self.P), self.F.t()) + self.Q\n",
    "    \n",
    "    def update(self, measurement):\n",
    "        y = measurement - torch.matmul(self.H, self.state)\n",
    "        S = torch.matmul(torch.matmul(self.H, self.P), self.H.t()) + self.R\n",
    "        K = torch.matmul(torch.matmul(self.P, self.H.t()), torch.inverse(S))\n",
    "        self.state = self.state + torch.matmul(K, y)\n",
    "        self.P = self.P - torch.matmul(torch.matmul(K, self.H), self.P)\n",
    "\n",
    "def setup_kalman_filter(initial_state, use_full_pose=False):\n",
    "    state_dim = 12 if use_full_pose else 3\n",
    "    measurement_dim = 12 if use_full_pose else 3\n",
    "\n",
    "    # State transition matrix (assume constant velocity model)\n",
    "    F = torch.eye(state_dim * 2)\n",
    "    if use_full_pose:\n",
    "        # Add velocity components for each pose element\n",
    "        for i in range(12):\n",
    "            F[i, i+12] = 1  # dt is assumed to be 1\n",
    "    else:\n",
    "        F[:3, 3:] = torch.eye(3)  # dt is assumed to be 1\n",
    "\n",
    "    # Measurement matrix\n",
    "    H = torch.eye(measurement_dim, state_dim * 2)\n",
    "\n",
    "    # Initial state covariance\n",
    "    P = torch.eye(state_dim * 2) * 0.1\n",
    "\n",
    "    # Process noise covariance\n",
    "    Q = torch.eye(state_dim * 2) * 0.01\n",
    "\n",
    "    # Measurement noise covariance\n",
    "    R = torch.eye(measurement_dim) * 0.1\n",
    "\n",
    "    return KalmanFilter(initial_state, P, F, H, Q, R)\n",
    "\n",
    "# Load and prepare data\n",
    "poses = load_poses('./data/Replica/room1/traj.txt', sc_factor=1.0)\n",
    "\n",
    "# Choose whether to use full pose or just position\n",
    "use_full_pose = False  # Set to True to use full pose\n",
    "\n",
    "# Convert poses to state vectors\n",
    "state_vectors = torch.stack([matrix_to_vector(pose, use_full_pose) for pose in poses])\n",
    "\n",
    "# Add some noise to the measurements\n",
    "noise_std_dev = 0.01\n",
    "noisy_state_vectors = state_vectors + torch.randn_like(state_vectors) * noise_std_dev\n",
    "\n",
    "# Initialize Kalman Filter\n",
    "initial_state = torch.zeros(24 if use_full_pose else 6)\n",
    "initial_state[:state_vectors.shape[1]] = state_vectors[0]\n",
    "kf = setup_kalman_filter(initial_state, use_full_pose)\n",
    "\n",
    "# Apply Kalman Filter\n",
    "filtered_states = []\n",
    "for state in noisy_state_vectors:\n",
    "    kf.predict()\n",
    "    kf.update(state)\n",
    "    filtered_states.append(kf.state[:state_vectors.shape[1]])\n",
    "\n",
    "filtered_states = torch.stack(filtered_states)\n",
    "\n",
    "# Extract positions for plotting\n",
    "if use_full_pose:\n",
    "    true_positions = state_vectors[:, [9, 10, 11]]\n",
    "    noisy_positions = noisy_state_vectors[:, [9, 10, 11]]\n",
    "    filtered_positions = filtered_states[:, [9, 10, 11]]\n",
    "else:\n",
    "    true_positions = state_vectors\n",
    "    noisy_positions = noisy_state_vectors\n",
    "    filtered_positions = filtered_states\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "true_positions = true_positions.numpy()\n",
    "noisy_positions = noisy_positions.numpy()\n",
    "filtered_positions = filtered_positions.numpy()\n",
    "\n",
    "# Plot results\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "# 3D plot\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "ax1.plot(true_positions[:, 0], true_positions[:, 1], true_positions[:, 2], 'g-', label='True Trajectory')\n",
    "ax1.plot(noisy_positions[:, 0], noisy_positions[:, 1], noisy_positions[:, 2], 'r.', label='Noisy Measurements')\n",
    "ax1.plot(filtered_positions[:, 0], filtered_positions[:, 1], filtered_positions[:, 2], 'b-', label='Kalman Filter Estimate')\n",
    "ax1.legend()\n",
    "ax1.set_title('3D Trajectory')\n",
    "ax1.set_xlabel('X position')\n",
    "ax1.set_ylabel('Y position')\n",
    "ax1.set_zlabel('Z position')\n",
    "\n",
    "# X-Y projection\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.plot(true_positions[:, 0], true_positions[:, 1], 'g-', label='True Trajectory')\n",
    "ax2.plot(noisy_positions[:, 0], noisy_positions[:, 1], 'r.', label='Noisy Measurements')\n",
    "ax2.plot(filtered_positions[:, 0], filtered_positions[:, 1], 'b-', label='Kalman Filter Estimate')\n",
    "ax2.legend()\n",
    "ax2.set_title('X-Y Projection')\n",
    "ax2.set_xlabel('X position')\n",
    "ax2.set_ylabel('Y position')\n",
    "ax2.grid(True)\n",
    "\n",
    "# Y-Z projection\n",
    "ax3 = fig.add_subplot(133)\n",
    "ax3.plot(true_positions[:, 1], true_positions[:, 2], 'g-', label='True Trajectory')\n",
    "ax3.plot(noisy_positions[:, 1], noisy_positions[:, 2], 'r.', label='Noisy Measurements')\n",
    "ax3.plot(filtered_positions[:, 1], filtered_positions[:, 2], 'b-', label='Kalman Filter Estimate')\n",
    "ax3.legend()\n",
    "ax3.set_title('Y-Z Projection')\n",
    "ax3.set_xlabel('Y position')\n",
    "ax3.set_ylabel('Z position')\n",
    "ax3.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Number of poses processed: {len(poses)}\")\n",
    "print(f\"Noise standard deviation: {noise_std_dev}\")\n",
    "print(f\"Process noise covariance (Q) diagonal: {kf.Q.diag()[:5]}\")\n",
    "print(f\"Measurement noise covariance (R) diagonal: {kf.R.diag()[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b912fa",
   "metadata": {},
   "source": [
    "## Camera motion speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4448390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_poses_from_file(file_path):\n",
    "    poses = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            values = list(map(float, line.strip().split()))\n",
    "            pose = np.array(values).reshape(4, 4)\n",
    "            poses.append(pose)\n",
    "    return np.array(poses)\n",
    "\n",
    "def euclidean_distance(pos1, pos2):\n",
    "    return np.linalg.norm(pos1 - pos2)\n",
    "\n",
    "def compute_camera_speed(prev_pose, curr_pose, time_elapsed):\n",
    "    prev_pos = prev_pose[:3, 3]\n",
    "    curr_pos = curr_pose[:3, 3]\n",
    "    distance = euclidean_distance(prev_pos, curr_pos)\n",
    "    speed = distance / time_elapsed\n",
    "    return speed\n",
    "\n",
    "# Load poses from file\n",
    "file_path = './output/TUM/fr_desk/demo/estimated_trajectory.txt'\n",
    "poses = load_poses_from_file(file_path)\n",
    "\n",
    "# Set a fixed time elapsed between frames (you can adjust this value)\n",
    "time_elapsed = 0.1  # seconds\n",
    "\n",
    "# Calculate speeds\n",
    "speeds = []\n",
    "for i in range(1, len(poses)):\n",
    "    prev_pose = poses[i-1]\n",
    "    curr_pose = poses[i]\n",
    "    speed = compute_camera_speed(prev_pose, curr_pose, time_elapsed)\n",
    "    speeds.append(speed)\n",
    "\n",
    "# Plot the speeds\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(speeds)\n",
    "plt.title('Camera Speed over Time')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Speed (units/second)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Average speed: {np.mean(speeds):.4f} units/second\")\n",
    "print(f\"Max speed: {np.max(speeds):.4f} units/second\")\n",
    "print(f\"Min speed: {np.min(speeds):.4f} units/second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa7842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae239990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_tum_ground_truth_poses(file_path):\n",
    "    poses = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            data = line.split()\n",
    "            if len(data) != 8:\n",
    "                continue\n",
    "            timestamp = float(data[0])\n",
    "            tx, ty, tz = map(float, data[1:4])\n",
    "            qx, qy, qz, qw = map(float, data[4:8])\n",
    "            \n",
    "            # Convert quaternion to rotation matrix\n",
    "            R = quaternion_to_rotation_matrix([qw, qx, qy, qz])\n",
    "            \n",
    "            # Create 4x4 transformation matrix\n",
    "            T = np.eye(4)\n",
    "            T[:3, :3] = R\n",
    "            T[:3, 3] = [tx, ty, tz]\n",
    "            \n",
    "            poses.append((timestamp, T))\n",
    "    \n",
    "    # Sort poses by timestamp\n",
    "    poses.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Extract only the transformation matrices\n",
    "    pose_matrices = [pose[1] for pose in poses]\n",
    "    \n",
    "    return np.array(pose_matrices)\n",
    "\n",
    "def quaternion_to_rotation_matrix(q):\n",
    "    w, x, y, z = q\n",
    "    R = np.array([\n",
    "        [1 - 2*y*y - 2*z*z, 2*x*y - 2*z*w, 2*x*z + 2*y*w],\n",
    "        [2*x*y + 2*z*w, 1 - 2*x*x - 2*z*z, 2*y*z - 2*x*w],\n",
    "        [2*x*z - 2*y*w, 2*y*z + 2*x*w, 1 - 2*x*x - 2*y*y]\n",
    "    ])\n",
    "    return R\n",
    "\n",
    "\n",
    "\n",
    "def calculate_pose_error(gt_pose, est_pose):\n",
    "    # Translation error\n",
    "    trans_error = np.linalg.norm(gt_pose[:3, 3] - est_pose[:3, 3])\n",
    "    \n",
    "    # Rotation error\n",
    "    R_gt = Rotation.from_matrix(gt_pose[:3, :3])\n",
    "    R_est = Rotation.from_matrix(est_pose[:3, :3])\n",
    "    R_diff = R_gt.inv() * R_est\n",
    "    rot_error = R_diff.magnitude()\n",
    "    \n",
    "    return trans_error, rot_error\n",
    "\n",
    "# Load poses\n",
    "gt_poses = load_tum_ground_truth_poses('./data/TUM/rgbd_dataset_freiburg1_desk/groundtruth.txt')\n",
    "est_poses = load_poses_from_file('./output/TUM/fr_desk/demo/estimated_trajectory.txt')\n",
    "\n",
    "# Calculate errors and speeds\n",
    "trans_errors = []\n",
    "rot_errors = []\n",
    "speeds = []\n",
    "time_elapsed = 0.1  # adjust as needed\n",
    "\n",
    "for i in range(1, len(est_poses)):\n",
    "    trans_error, rot_error = calculate_pose_error(gt_poses[i], est_poses[i])\n",
    "    trans_errors.append(trans_error)\n",
    "    rot_errors.append(rot_error)\n",
    "    \n",
    "    speed = compute_camera_speed(est_poses[i-1], est_poses[i], time_elapsed)\n",
    "    speeds.append(speed)\n",
    "\n",
    "# Calculate correlations\n",
    "correlation_trans = np.corrcoef(speeds, trans_errors)[0, 1]\n",
    "correlation_rot = np.corrcoef(speeds, rot_errors)[0, 1]\n",
    "\n",
    "print(f\"Correlation between speed and translation error: {correlation_trans:.4f}\")\n",
    "print(f\"Correlation between speed and rotation error: {correlation_rot:.4f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(speeds, label='Speed')\n",
    "plt.plot(trans_errors, label='Translation Error')\n",
    "plt.legend()\n",
    "plt.title('Speed vs Translation Error')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(speeds, label='Speed')\n",
    "plt.plot(rot_errors, label='Rotation Error')\n",
    "plt.legend()\n",
    "plt.title('Speed vs Rotation Error')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac859b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20bd19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_tum_ground_truth_poses(file_path):\n",
    "    poses = []\n",
    "    timestamps = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            data = line.split()\n",
    "            if len(data) != 8:\n",
    "                continue\n",
    "            timestamp = float(data[0])\n",
    "            tx, ty, tz = map(float, data[1:4])\n",
    "            qx, qy, qz, qw = map(float, data[4:8])\n",
    "            \n",
    "            # Convert quaternion to rotation matrix\n",
    "            R = quaternion_to_rotation_matrix([qw, qx, qy, qz])\n",
    "            \n",
    "            # Create 4x4 transformation matrix\n",
    "            T = np.eye(4)\n",
    "            T[:3, :3] = R\n",
    "            T[:3, 3] = [tx, ty, tz]\n",
    "            \n",
    "            poses.append(T)\n",
    "            timestamps.append(timestamp)\n",
    "    \n",
    "    return np.array(poses), np.array(timestamps)\n",
    "\n",
    "def quaternion_to_rotation_matrix(q):\n",
    "    w, x, y, z = q\n",
    "    R = np.array([\n",
    "        [1 - 2*y*y - 2*z*z, 2*x*y - 2*z*w, 2*x*z + 2*y*w],\n",
    "        [2*x*y + 2*z*w, 1 - 2*x*x - 2*z*z, 2*y*z - 2*x*w],\n",
    "        [2*x*z - 2*y*w, 2*y*z + 2*x*w, 1 - 2*x*x - 2*y*y]\n",
    "    ])\n",
    "    return R\n",
    "\n",
    "# Usage\n",
    "gt_poses, gt_timestamps = load_tum_ground_truth_poses('./data/TUM/rgbd_dataset_freiburg3_long_office_household/groundtruth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea469bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_camera_speed(prev_pose, curr_pose, prev_time, curr_time):\n",
    "    prev_pos = prev_pose[:3, 3]\n",
    "    curr_pos = curr_pose[:3, 3]\n",
    "    distance = np.linalg.norm(curr_pos - prev_pos)\n",
    "    time_elapsed = curr_time - prev_time\n",
    "    speed = distance / time_elapsed\n",
    "    return speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe518d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load estimated poses\n",
    "est_poses = load_poses_from_file('./output/TUM/fr_office/demo/estimated_trajectory.txt')\n",
    "\n",
    "# Make sure we have the same number of poses\n",
    "min_poses = min(len(gt_poses), len(est_poses))\n",
    "gt_poses = gt_poses[:min_poses]\n",
    "est_poses = est_poses[:min_poses]\n",
    "timestamps = gt_timestamps[:min_poses]\n",
    "\n",
    "def compute_camera_speed(prev_pose, curr_pose, prev_time, curr_time):\n",
    "    prev_pos = prev_pose[:3, 3]\n",
    "    curr_pos = curr_pose[:3, 3]\n",
    "    distance = np.linalg.norm(curr_pos - prev_pos)\n",
    "    time_elapsed = curr_time - prev_time\n",
    "    speed = distance / time_elapsed\n",
    "    return speed\n",
    "\n",
    "def calculate_pose_error(gt_pose, est_pose):\n",
    "    # Translation error\n",
    "    trans_error = np.linalg.norm(gt_pose[:3, 3] - est_pose[:3, 3])\n",
    "    \n",
    "    # Rotation error\n",
    "    R_gt = gt_pose[:3, :3]\n",
    "    R_est = est_pose[:3, :3]\n",
    "    R_diff = np.dot(R_gt.T, R_est)\n",
    "    rot_error = np.arccos((np.trace(R_diff) - 1) / 2)\n",
    "    \n",
    "    return trans_error, rot_error\n",
    "\n",
    "# Calculate speeds and errors\n",
    "speeds = []\n",
    "trans_errors = []\n",
    "rot_errors = []\n",
    "\n",
    "for i in range(1, len(est_poses)):\n",
    "    # Calculate speed\n",
    "    speed = compute_camera_speed(est_poses[i-1], est_poses[i], timestamps[i-1], timestamps[i])\n",
    "    speeds.append(speed)\n",
    "    \n",
    "    # Calculate pose error\n",
    "    trans_error, rot_error = calculate_pose_error(gt_poses[i], est_poses[i])\n",
    "    trans_errors.append(trans_error)\n",
    "    rot_errors.append(rot_error)\n",
    "\n",
    "# Calculate correlations\n",
    "correlation_trans = np.corrcoef(speeds, trans_errors)[0, 1]\n",
    "correlation_rot = np.corrcoef(speeds, rot_errors)[0, 1]\n",
    "\n",
    "print(f\"Correlation between speed and translation error: {correlation_trans:.4f}\")\n",
    "print(f\"Correlation between speed and rotation error: {correlation_rot:.4f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(timestamps[1:], speeds, label='Speed')\n",
    "plt.plot(timestamps[1:], trans_errors, label='Translation Error')\n",
    "plt.legend()\n",
    "plt.title('Speed vs Translation Error')\n",
    "plt.xlabel('Time (s)')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(timestamps[1:], speeds, label='Speed')\n",
    "plt.plot(timestamps[1:], rot_errors, label='Rotation Error')\n",
    "plt.legend()\n",
    "plt.title('Speed vs Rotation Error')\n",
    "plt.xlabel('Time (s)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Average speed: {np.mean(speeds):.4f} units/second\")\n",
    "print(f\"Max speed: {np.max(speeds):.4f} units/second\")\n",
    "print(f\"Min speed: {np.min(speeds):.4f} units/second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631caf73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58600250",
   "metadata": {},
   "source": [
    "## Calculate Motion for Replica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da62e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_poses_from_file(file_path):\n",
    "    poses = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            values = list(map(float, line.strip().split()))\n",
    "            pose = np.array(values).reshape(4, 4)\n",
    "            poses.append(pose)\n",
    "    return np.array(poses)\n",
    "\n",
    "def load_replica_ground_truth_poses(file_path):\n",
    "    return load_poses_from_file(file_path)\n",
    "\n",
    "def compute_camera_speed(prev_pose, curr_pose, time_elapsed):\n",
    "    prev_pos = prev_pose[:3, 3]\n",
    "    curr_pos = curr_pose[:3, 3]\n",
    "    distance = np.linalg.norm(curr_pos - prev_pos)\n",
    "    speed = distance / time_elapsed\n",
    "    return speed\n",
    "\n",
    "def calculate_pose_error(gt_pose, est_pose):\n",
    "    # Translation error\n",
    "    trans_error = np.linalg.norm(gt_pose[:3, 3] - est_pose[:3, 3])\n",
    "    \n",
    "    # Rotation error\n",
    "    R_gt = gt_pose[:3, :3]\n",
    "    R_est = est_pose[:3, :3]\n",
    "    R_diff = np.dot(R_gt.T, R_est)\n",
    "    rot_error = np.arccos(np.clip((np.trace(R_diff) - 1) / 2, -1, 1))\n",
    "    \n",
    "    return trans_error, rot_error\n",
    "\n",
    "def analyze_trajectory(gt_path, est_path, time_step=0.1):\n",
    "    # Load poses\n",
    "    gt_poses = load_replica_ground_truth_poses(gt_path)\n",
    "    est_poses = load_poses_from_file(est_path)\n",
    "\n",
    "    # Make sure we have the same number of poses\n",
    "    min_poses = min(len(gt_poses), len(est_poses))\n",
    "    gt_poses = gt_poses[:min_poses]\n",
    "    est_poses = est_poses[:min_poses]\n",
    "\n",
    "    # Calculate speeds and errors\n",
    "    speeds = []\n",
    "    trans_errors = []\n",
    "    rot_errors = []\n",
    "\n",
    "    for i in range(1, len(est_poses)):\n",
    "        speed = compute_camera_speed(est_poses[i-1], est_poses[i], time_step)\n",
    "        speeds.append(speed)\n",
    "        \n",
    "        trans_error, rot_error = calculate_pose_error(gt_poses[i], est_poses[i])\n",
    "        trans_errors.append(trans_error)\n",
    "        rot_errors.append(rot_error)\n",
    "\n",
    "    # Calculate correlations\n",
    "    correlation_trans = np.corrcoef(speeds, trans_errors)[0, 1]\n",
    "    correlation_rot = np.corrcoef(speeds, rot_errors)[0, 1]\n",
    "\n",
    "    # Plot\n",
    "    time_points = np.arange(len(speeds)) * time_step\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(time_points, speeds, label='Speed')\n",
    "    plt.plot(time_points, trans_errors, label='Translation Error')\n",
    "    plt.legend()\n",
    "    plt.title('Speed vs Translation Error')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Units')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(time_points, speeds, label='Speed')\n",
    "    plt.plot(time_points, rot_errors, label='Rotation Error')\n",
    "    plt.legend()\n",
    "    plt.title('Speed vs Rotation Error')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Units')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"Correlation between speed and translation error: {correlation_trans:.4f}\")\n",
    "    print(f\"Correlation between speed and rotation error: {correlation_rot:.4f}\")\n",
    "    print(f\"Average speed: {np.mean(speeds):.4f} units/second\")\n",
    "    print(f\"Max speed: {np.max(speeds):.4f} units/second\")\n",
    "    print(f\"Min speed: {np.min(speeds):.4f} units/second\")\n",
    "    print(f\"Average translation error: {np.mean(trans_errors):.4f} units\")\n",
    "    print(f\"Average rotation error: {np.mean(rot_errors):.4f} radians\")\n",
    "\n",
    "    return speeds, trans_errors, rot_errors\n",
    "\n",
    "# Usage in Jupyter Notebook\n",
    "# Just run this cell to define all functions\n",
    "\n",
    "# Then in a new cell, you can simply call:\n",
    "# analyze_trajectory('path/to/ground_truth.txt', 'path/to/estimated_trajectory.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c98399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a single scene\n",
    "scene_name = \"room1\"\n",
    "\n",
    "gt_path = f\"./data/Replica/{scene_name}/traj.txt\"\n",
    "est_path = f\"./output/Replica/{scene_name}/demo/estimated_trajectory.txt\"\n",
    "\n",
    "speeds, trans_errors, rot_errors = analyze_trajectory(gt_path, est_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe5eb23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
